{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "02Linear_regression.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ou7JHYOCsfoT"
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sy2c6RNsohiz"
      },
      "source": [
        "#Data\n",
        "x_data = np.array([1.,2.,3.,4.,5.])\n",
        "y_data = np.array([1.,2.,3.,4.,5.])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "20SEcomcrbs1"
      },
      "source": [
        "#W, b\n",
        "W = np.random.uniform(0,10)\n",
        "b = np.random.uniform(0,10)\n",
        "\n",
        "#Hypothesis = Wx +b\n",
        "hypothesis = W*x_data + b"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CtFxgU8jr3mM"
      },
      "source": [
        "# Cost Function\n",
        "def Cost(x,y,w,b):\n",
        "  hypothesis = w*x + b\n",
        "  cost = sum(pow(hypothesis-y,2))/len(y)\n",
        "  return cost"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c-HdeSuSuWwA"
      },
      "source": [
        "#Grad W, b\n",
        "def Grad_W(x,y,w,b):\n",
        "  return 2*sum((w*x+b-y)*x)/len(y)\n",
        "\n",
        "def Grad_b(x,y,w,b):\n",
        "  return 2*sum(w*x+b-y)/len(y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VdhzIRqryd2G"
      },
      "source": [
        "def Train(x,y,epochs=100,learning_rate=0.01):\n",
        "  W = np.random.uniform(0,10)\n",
        "  b = np.random.uniform(0,10)\n",
        "#  print(\"Initial W and b : \",W,b)\n",
        "  for i in range(epochs):\n",
        "    g_W = Grad_W(x,y,W,b)\n",
        "    g_b = Grad_b(x,y,W,b)\n",
        "    W -= learning_rate*g_W\n",
        "    b -= learning_rate*g_b\n",
        "    cost = Cost(x,y,W,b)\n",
        "    if i%10 == 0 :\n",
        "      print(\"{:5} | {:10.4} | {:10.4} | {:10.6f}\".format(i,W,b,cost))\n",
        "  return W,b"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S-yABDJ73s5G",
        "outputId": "8a9c4701-ce1f-4f7e-81b7-4a6ae938526e"
      },
      "source": [
        "Train(x_data,y_data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "    0 |      2.868 |      2.326 |  69.868676\n",
            "   10 |      0.707 |      1.667 |   0.793272\n",
            "   20 |     0.5757 |      1.573 |   0.449991\n",
            "   30 |     0.5804 |      1.518 |   0.419205\n",
            "   40 |     0.5937 |      1.467 |   0.391745\n",
            "   50 |     0.6072 |      1.418 |   0.366089\n",
            "   60 |     0.6203 |      1.371 |   0.342114\n",
            "   70 |     0.6329 |      1.325 |   0.319708\n",
            "   80 |     0.6451 |      1.281 |   0.298770\n",
            "   90 |     0.6569 |      1.239 |   0.279204\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.6672475797179644, 1.2013418190116945)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gUBZdqaq47ji",
        "outputId": "8d0d3e92-c383-4570-eb92-331b4daf8e6e"
      },
      "source": [
        "t_W,t_b = Train(x_data,y_data,1000,0.01)\n",
        "print(t_W * 5 + t_b)\n",
        "print(t_W * 2.5 + t_b)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "    0 |      5.213 |      8.836 | 496.717487\n",
            "   10 |    -0.4913 |        7.0 |  10.829815\n",
            "   20 |    -0.8156 |      6.663 |   8.072858\n",
            "   30 |    -0.7802 |      6.435 |   7.534911\n",
            "   40 |    -0.7226 |       6.22 |   7.041402\n",
            "   50 |    -0.6654 |      6.013 |   6.580255\n",
            "   60 |    -0.6099 |      5.812 |   6.149309\n",
            "   70 |    -0.5563 |      5.619 |   5.746586\n",
            "   80 |    -0.5045 |      5.432 |   5.370237\n",
            "   90 |    -0.4544 |      5.251 |   5.018536\n",
            "  100 |     -0.406 |      5.076 |   4.689868\n",
            "  110 |    -0.3592 |      4.907 |   4.382725\n",
            "  120 |    -0.3139 |      4.744 |   4.095697\n",
            "  130 |    -0.2701 |      4.586 |   3.827466\n",
            "  140 |    -0.2279 |      4.433 |   3.576802\n",
            "  150 |     -0.187 |      4.285 |   3.342555\n",
            "  160 |    -0.1474 |      4.143 |   3.123648\n",
            "  170 |    -0.1092 |      4.005 |   2.919078\n",
            "  180 |   -0.07229 |      3.871 |   2.727905\n",
            "  190 |   -0.03658 |      3.742 |   2.549252\n",
            "  200 |  -0.002066 |      3.618 |   2.382300\n",
            "  210 |     0.0313 |      3.497 |   2.226281\n",
            "  220 |    0.06356 |      3.381 |   2.080480\n",
            "  230 |    0.09474 |      3.268 |   1.944228\n",
            "  240 |     0.1249 |      3.159 |   1.816899\n",
            "  250 |      0.154 |      3.054 |   1.697909\n",
            "  260 |     0.1822 |      2.953 |   1.586711\n",
            "  270 |     0.2094 |      2.854 |   1.482796\n",
            "  280 |     0.2358 |      2.759 |   1.385687\n",
            "  290 |     0.2612 |      2.667 |   1.294937\n",
            "  300 |     0.2858 |      2.578 |   1.210131\n",
            "  310 |     0.3096 |      2.493 |   1.130878\n",
            "  320 |     0.3326 |       2.41 |   1.056816\n",
            "  330 |     0.3548 |      2.329 |   0.987604\n",
            "  340 |     0.3763 |      2.252 |   0.922925\n",
            "  350 |     0.3971 |      2.177 |   0.862482\n",
            "  360 |     0.4171 |      2.104 |   0.805998\n",
            "  370 |     0.4365 |      2.034 |   0.753212\n",
            "  380 |     0.4553 |      1.966 |   0.703884\n",
            "  390 |     0.4734 |      1.901 |   0.657786\n",
            "  400 |      0.491 |      1.838 |   0.614707\n",
            "  410 |     0.5079 |      1.777 |   0.574449\n",
            "  420 |     0.5243 |      1.717 |   0.536828\n",
            "  430 |     0.5402 |       1.66 |   0.501671\n",
            "  440 |     0.5555 |      1.605 |   0.468816\n",
            "  450 |     0.5703 |      1.551 |   0.438113\n",
            "  460 |     0.5846 |        1.5 |   0.409420\n",
            "  470 |     0.5984 |       1.45 |   0.382607\n",
            "  480 |     0.6118 |      1.402 |   0.357550\n",
            "  490 |     0.6247 |      1.355 |   0.334134\n",
            "  500 |     0.6372 |       1.31 |   0.312251\n",
            "  510 |     0.6493 |      1.266 |   0.291801\n",
            "  520 |      0.661 |      1.224 |   0.272691\n",
            "  530 |     0.6723 |      1.183 |   0.254832\n",
            "  540 |     0.6832 |      1.144 |   0.238143\n",
            "  550 |     0.6937 |      1.106 |   0.222547\n",
            "  560 |     0.7039 |      1.069 |   0.207972\n",
            "  570 |     0.7138 |      1.033 |   0.194352\n",
            "  580 |     0.7233 |     0.9989 |   0.181624\n",
            "  590 |     0.7325 |     0.9657 |   0.169729\n",
            "  600 |     0.7414 |     0.9335 |   0.158613\n",
            "  610 |       0.75 |     0.9024 |   0.148226\n",
            "  620 |     0.7584 |     0.8724 |   0.138518\n",
            "  630 |     0.7664 |     0.8433 |   0.129447\n",
            "  640 |     0.7742 |     0.8152 |   0.120969\n",
            "  650 |     0.7817 |     0.7881 |   0.113047\n",
            "  660 |      0.789 |     0.7618 |   0.105643\n",
            "  670 |      0.796 |     0.7365 |   0.098724\n",
            "  680 |     0.8028 |     0.7119 |   0.092259\n",
            "  690 |     0.8094 |     0.6882 |   0.086217\n",
            "  700 |     0.8157 |     0.6653 |   0.080570\n",
            "  710 |     0.8219 |     0.6432 |   0.075294\n",
            "  720 |     0.8278 |     0.6217 |   0.070363\n",
            "  730 |     0.8335 |      0.601 |   0.065755\n",
            "  740 |     0.8391 |      0.581 |   0.061448\n",
            "  750 |     0.8444 |     0.5617 |   0.057424\n",
            "  760 |     0.8496 |      0.543 |   0.053663\n",
            "  770 |     0.8546 |     0.5249 |   0.050149\n",
            "  780 |     0.8595 |     0.5074 |   0.046865\n",
            "  790 |     0.8641 |     0.4905 |   0.043795\n",
            "  800 |     0.8687 |     0.4742 |   0.040927\n",
            "  810 |      0.873 |     0.4584 |   0.038247\n",
            "  820 |     0.8773 |     0.4431 |   0.035742\n",
            "  830 |     0.8813 |     0.4284 |   0.033401\n",
            "  840 |     0.8853 |     0.4141 |   0.031214\n",
            "  850 |     0.8891 |     0.4003 |   0.029170\n",
            "  860 |     0.8928 |      0.387 |   0.027259\n",
            "  870 |     0.8964 |     0.3741 |   0.025474\n",
            "  880 |     0.8998 |     0.3616 |   0.023806\n",
            "  890 |     0.9032 |     0.3496 |   0.022247\n",
            "  900 |     0.9064 |      0.338 |   0.020790\n",
            "  910 |     0.9095 |     0.3267 |   0.019428\n",
            "  920 |     0.9125 |     0.3158 |   0.018156\n",
            "  930 |     0.9154 |     0.3053 |   0.016967\n",
            "  940 |     0.9182 |     0.2951 |   0.015856\n",
            "  950 |      0.921 |     0.2853 |   0.014817\n",
            "  960 |     0.9236 |     0.2758 |   0.013847\n",
            "  970 |     0.9261 |     0.2666 |   0.012940\n",
            "  980 |     0.9286 |     0.2578 |   0.012092\n",
            "  990 |      0.931 |     0.2492 |   0.011301\n",
            "4.906969370368871\n",
            "2.574328850191323\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}